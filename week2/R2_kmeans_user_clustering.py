'''
Author: TonyInBeijing
Date: 2025-10-15 19:05:01
LastEditors: TonyInBeijing
LastEditTime: 2025-10-16 21:49:44
FilePath: /geektime/homework/week2/R2_kmeans_user_clustering.py
Description: ä½œä¸šäºŒï¼šåŸºäº K-Means çš„ç”¨æˆ·åˆ†ç¾¤ä¸ç”»åƒæ´å¯Ÿ

'''
import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sentence_transformers import SentenceTransformer
import plotly.express as px
import plotly.graph_objects as go
from scipy.spatial.distance import cdist

FILE_PATH = "../week1/user_profiles.csv"
MODEL_NAME = "BAAI/bge-m3"
CAT_COLS = ["æ€§åˆ«", "æ‰€åœ¨åŸå¸‚", "æ¶ˆè´¹æ°´å¹³"]
NUM_COLS = ["å¹´é¾„", "æœ€è¿‘æ´»è·ƒå¤©æ•°"]
N_CLUSTERS_RANGE = range(2, 11)

data = pd.read_csv(FILE_PATH)
model = SentenceTransformer(MODEL_NAME)

cat_vectors = []
for col in CAT_COLS:
    vectors = model.encode(data[col].astype(str).tolist())
    cat_vectors.append(vectors)

num_vectors = data[NUM_COLS].values
user_matrix = np.hstack(cat_vectors + [num_vectors])
print(f"ç‰¹å¾æ‹¼æ¥åå½¢çŠ¶: {user_matrix.shape}")

scaler = StandardScaler()
user_matrix_standard = scaler.fit_transform(user_matrix)

k = 3

final_kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
cluster_labels = final_kmeans.fit_predict(user_matrix_standard)
centroids = final_kmeans.cluster_centers_


# æ‰¾å‡ºæ¯ä¸ªç°‡ä¸­ç¦»è´¨å¿ƒæœ€è¿‘çš„çœŸå®ç”¨æˆ·
representative_indices = []   # æ¯ä¸ªç°‡çš„ä»£è¡¨ç”¨æˆ·ç´¢å¼•
for cid in range(k):
    # å–è¯¥ç°‡æ‰€æœ‰æ ·æœ¬çš„ç´¢å¼•
    idxs = np.where(cluster_labels == cid)[0]
    if len(idxs) == 0:
        continue
    # å–å‡ºè¿™äº›æ ·æœ¬åœ¨æ ‡å‡†åŒ–ç©ºé—´çš„å‘é‡
    cluster_vectors = user_matrix_standard[idxs]
    # è®¡ç®—è¿™äº›æ ·æœ¬åˆ°ç°‡è´¨å¿ƒ cid çš„è·ç¦»ï¼ˆæ¬§æ°ï¼‰
    dists = cdist(cluster_vectors, centroids[cid].reshape(1, -1), metric='euclidean').reshape(-1)
    # æ‰¾åˆ°æœ€å°è·ç¦»å¯¹åº”çš„æ ·æœ¬ï¼ˆçœŸå®ç´¢å¼•ï¼‰
    min_local_idx = np.argmin(dists)
    rep_idx = idxs[min_local_idx]
    representative_indices.append(rep_idx)
    # æ‰“å°ä»£è¡¨ç”¨æˆ·ä¿¡æ¯ï¼ˆå®Œæ•´è¡Œï¼‰
    print(f"\n=== ç°‡ {cid} çš„ä»£è¡¨ç”¨æˆ·ï¼ˆæ ·æœ¬ç´¢å¼• {rep_idx}ï¼‰ ===")
    print(data.iloc[rep_idx].to_dict())





data_clustered = data.copy()
data_clustered["èšç±»æ ‡ç­¾"] = cluster_labels
print(data_clustered["èšç±»æ ‡ç­¾"].value_counts())

cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()

for cluster_id, count in cluster_counts.items():
    print(f"  èšç±» {cluster_id}: {count} ç”¨æˆ·")

print("\nè¿›è¡ŒPCAé™ç»´...")
pca = PCA(n_components=3)
user_3d = pca.fit_transform(user_matrix_standard)
centroids_3d = pca.transform(centroids)

exp_var = pca.explained_variance_ratio_
print(f"PCAå‰3ä¸ªä¸»æˆåˆ†è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹: {exp_var}")
print(f"ç´¯è®¡è§£é‡Šæ–¹å·®: {np.sum(exp_var):.2%}")

# --- 7. äº¤äº’å¼3Då¯è§†åŒ– ---
print("\nç”Ÿæˆäº¤äº’å¼3Dèšç±»å¯è§†åŒ–...")
df_plot = data_clustered.copy()
df_plot['PC1'] = user_3d[:, 0]
df_plot['PC2'] = user_3d[:, 1]
df_plot['PC3'] = user_3d[:, 2]

# ç”¨æˆ·ç‚¹
fig3d = px.scatter_3d(
    df_plot, x='PC1', y='PC2', z='PC3',
    color='èšç±»æ ‡ç­¾',
    hover_data=CAT_COLS + NUM_COLS,
    title='K-meansèšç±»ç»“æœäº¤äº’å¼å¯è§†åŒ–',
    color_discrete_sequence=px.colors.qualitative.Set1
)

# æ·»åŠ èšç±»ä¸­å¿ƒç‚¹
centroids_df = pd.DataFrame({
    'PC1': centroids_3d[:, 0],
    'PC2': centroids_3d[:, 1],
    'PC3': centroids_3d[:, 2],
    'èšç±»ä¸­å¿ƒ': [f'ä¸­å¿ƒ{i}' for i in range(k)]
})

fig3d.add_trace(go.Scatter3d(
    x=centroids_df['PC1'],
    y=centroids_df['PC2'],
    z=centroids_df['PC3'],
    mode='markers+text',
    marker=dict(size=15, color='red', symbol='x'),
    text=centroids_df['èšç±»ä¸­å¿ƒ'],
    textposition='top center',
    name='èšç±»ä¸­å¿ƒ',
    showlegend=True
))

fig3d.show()

print("\nğŸ¯ äº¤äº’å¼3Då¯è§†åŒ–å·²ç”Ÿæˆï¼")
print("   â€¢ å¯ä»¥æ—‹è½¬ã€ç¼©æ”¾ã€ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
print("   â€¢ çº¢è‰²Xæ ‡è®°ä¸ºå„èšç±»ä¸­å¿ƒç‚¹")
print("   â€¢ ä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒèšç±»")

# --- 8. ä¿å­˜ç»“æœ ---
# ä¿å­˜èšç±»ç»“æœ
data_clustered.to_csv('user_clustering_results.csv', index=False)
print(f"\nğŸ“ èšç±»ç»“æœå·²ä¿å­˜åˆ° user_clustering_results.csv")

# è®¡ç®—æœ€ç»ˆèšç±»çš„è½®å»“ç³»æ•°
final_silhouette_score = silhouette_score(user_matrix_standard, cluster_labels)

print(f"\n=== âœ… K-meansèšç±»åˆ†æå®Œæˆ ===")
print(f"ğŸ“Š èšç±»æ•°é‡: {k}")
print(f"ğŸ¯ è½®å»“ç³»æ•°: {final_silhouette_score:.3f}")
print(f"ğŸ“ˆ PCAç´¯è®¡è§£é‡Šæ–¹å·®: {np.sum(exp_var):.2%}")
